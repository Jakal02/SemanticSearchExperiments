"""
Main file for running backend api.
"""
from typing import Annotated
from contextlib import asynccontextmanager
from fastapi import FastAPI, Depends
from fastapi.middleware.cors import CORSMiddleware
from starlette.responses import HTMLResponse
from starlette.staticfiles import StaticFiles
from sqlalchemy.orm import Session

from frage import models
from frage.models import Post, PostCreate, PostRetrieve
from frage.database import engine, SessionLocal


# tables should be created with alembic
@asynccontextmanager
async def lifespan(frage: FastAPI):
    models.Base.metadata.create_all(bind=engine)
    yield


app = FastAPI(title="Svar Backend", lifespan=lifespan)

import os
from elasticsearch import Elasticsearch
# Password for the 'elastic' user generated by Elasticsearch
ELASTIC_PASSWORD = os.environ["ELASTIC_PASSWORD"]
# Create the client instance
client = Elasticsearch(
    "https://localhost:9200",
    ca_certs="./other_http_ca.crt",
    basic_auth=("elastic", ELASTIC_PASSWORD)
)

from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')

POST_INDEX = "post_index"


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

SessionDep = Annotated[Session, Depends(get_db)]


@app.get("/")
def hello(db: SessionDep):
    num_posts = db.query(Post).count()
    return {"Hello":num_posts}

@app.get("/post_index/")
def hello(db: SessionDep):
    num_posts = client.count(index=POST_INDEX)
    return {"Hello":num_posts}


@app.post("/clear-create-post-index/")
def clear_create_post_index():
    client.indices.delete(index=POST_INDEX, ignore_unavailable=True)
    mappings = {
        "properties": {
            "post_content_vector": {
                "type": "dense_vector",
                "dims": 384,
                "index": "true",
                "similarity": "cosine"
            }
        }
    }
    # Create the index
    result = client.indices.create(index=POST_INDEX, mappings=mappings)
    return result


@app.get("/post/{id}/")
def get_post(id: int, db: SessionDep):
    return db.query(Post).filter(Post.id == id).first()


@app.post("/post/")
def create_post(post_data: PostCreate, db:SessionDep):
    db_post = models.Post(**post_data.model_dump())
    db.add(db_post)
    db.commit()
    db.refresh(db_post)
    
    # Encode
    text = db_post.title + "\n" + db_post.body
    encoding = model.encode(text)
    # Add to elastic search
    doc_data = PostRetrieve(**db_post.__dict__).model_dump()
    doc_data['post_content_vector'] = encoding
    client.index(index=POST_INDEX, id=doc_data['id'], document=doc_data)

    return db_post


@app.delete("/post/{id}/")
def delete_post(id: int, db: SessionDep):
    db_post = db.query(Post).filter(Post.id == id).first()
    if db_post is None:
        return None
    db.delete(db_post)
    db.commit()
    client.delete(index=POST_INDEX, id=db_post.id)

    return db_post


@app.get("/sem_search/")
def semantic_search(query: str):
    response = client.search(
                        index=POST_INDEX,
                        knn={
                        "field": "post_content_vector",
                        "query_vector": model.encode(query),
                        "k": 10,
                        "num_candidates": 100
                        },
                        _source = ["title","body"],
                    )

    return response
